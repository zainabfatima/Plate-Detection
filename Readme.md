# ğŸ§ª Microplate Detection using YOLOv5

This project performs **object detection on ELISA microplates** using the **YOLOv5 deep learning model**. It detects and classifies microplate wells into three categories:
- âœ… Positive
- âŒ Negative
- âšª Buffer

The project includes **custom dataset preparation**, **YOLO training**, **inference**, and **model export (TFLite)** for Android deployment.

---

## ğŸš€ Features

- ğŸ“¦ Custom dataset conversion from Pascal VOC XML â†’ YOLOv5 format
- ğŸ¯ Object detection with 3 custom microplate classes
- ğŸ§  Training using YOLOv5s backbone (lightweight)
- ğŸ–¼ï¸ Visual test inference results on custom dataset
- ğŸ“¤ Model export to `.tflite` for mobile deployment
- ğŸ“Š Training metrics available via YOLO `runs/`

---

## ğŸ“ File Structure

Microplate-detection-using-YOLOv5/
â”œâ”€â”€ YoloV5_Microplate.ipynb # Full training + inference pipeline in Colab
â”œâ”€â”€ Readme.md # This documentation file
â”œâ”€â”€ Report.docx # Report describing the project results
â”œâ”€â”€ yolov5/ # YOLOv5 source (cloned from Ultralytics)
â”‚ â”œâ”€â”€ train.py # YOLO training script
â”‚ â”œâ”€â”€ detect.py # Run inference on images
â”‚ â”œâ”€â”€ export.py # Export model (TFLite, TorchScript, etc.)
â”‚ â””â”€â”€ ... # Other internal YOLOv5 components
â”œâ”€â”€ dataset_YOLO/ # Generated YOLO-ready dataset (after conversion)
â”‚ â”œâ”€â”€ Train/
â”‚ â”œâ”€â”€ Val/
â”‚ â”œâ”€â”€ Test/
â”‚ â””â”€â”€ data.yaml # YOLO dataset config file
â””â”€â”€ best-fp16.tflite # âœ… Trained YOLOv5 model ready for Android

yaml
Copy
Edit

---

## ğŸ“¥ Dataset

To train or retrain the model, download the dataset here:

ğŸ”— [Eliza Microplate Dataset (Google Drive)](https://drive.google.com/drive/folders/18U0gQetGk9y2s-UF7RaHBKSA-EdTk3Zr?usp=drive_link)

Expected folder structure:

Eliza Microplates DATASET/
â”œâ”€â”€ images/
â”‚ â”œâ”€â”€ positive/
â”‚ â”œâ”€â”€ negative/
â”‚ â””â”€â”€ buffer/
â””â”€â”€ vocxml/
â”œâ”€â”€ positive/
â”œâ”€â”€ negative/
â””â”€â”€ buffer/

yaml
Copy
Edit

---

## ğŸ›  How to Run

> âš™ï¸ The entire workflow is provided in the notebook: `YoloV5_Microplate.ipynb`

### 1. ğŸ Setup

If you're running outside Google Colab, install required libraries:

```bash
pip install -r yolov5/requirements.txt
pip install opencv-python numpy pandas scikit-learn PyYAML
2. ğŸ’½ Convert Dataset (already done in notebook)
Extract annotations from XML

Convert to YOLO format using provided code

Saves output to dataset_YOLO/Train, Val, and Test

3. ğŸ‹ï¸â€â™€ï¸ Train the Model
From inside yolov5/ directory:

bash
Copy
Edit
python train.py --img 736 --batch 16 --epochs 35 \
--data ../dataset_YOLO/data.yaml --weights yolov5s.pt --cache
Training artifacts will be saved to:

swift
Copy
Edit
yolov5/runs/train/exp/
4. ğŸ” Run Inference
bash
Copy
Edit
python detect.py --weights runs/train/exp/weights/best.pt \
--img 1080 --conf 0.1 --source ../dataset_YOLO/Test/images
Resulting images with bounding boxes will be saved in:

swift
Copy
Edit
yolov5/runs/detect/exp/
5. ğŸ“¤ Export to TFLite (for Android)
bash
Copy
Edit
python export.py --weights runs/train/exp/weights/best.pt --include tflite
Output:

swift
Copy
Edit
runs/train/exp/weights/best-fp16.tflite
ğŸ“¸ Output Example
âœ… YOLO detects bounding boxes over wells

ğŸ” Classifies as "positive", "negative", or "buffer"

ğŸ“‚ Results saved as images inside runs/detect/exp/

ğŸ§ª Can be deployed to Android for real-time inference

ğŸ“² Deployment (Android Studio)
You can use the exported best-fp16.tflite model in a mobile app using TensorFlow Lite and CameraX.

ğŸ“Š Model Performance
Training summary available in Report.docx

Evaluation metrics include mAP, precision, recall

Inference is fast and lightweight using YOLOv5s
